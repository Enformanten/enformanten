{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes\n",
    "\n",
    "- IAQ = Indoor Air Quality\n",
    "- SKEMALAGT = Room-time scheduled in school timetable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "\n",
    "# anomaly detection\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "# settings\n",
    "pd.options.plotting.backend = \"plotly\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SENSOR_COLUMNS = [\"CO2\", \"TEMP\", \"MOTION\", \"IAQ\", \"BOOKET\"]\n",
    "KOMMUNE = \"Aarhus\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diagnose(df, col, dfunc=\"unique\", **kwargs):\n",
    "    print(getattr(df[col], dfunc)(**kwargs))\n",
    "    return df\n",
    "\n",
    "def fill_na(df, cols, values, types):\n",
    "    return df.assign(\n",
    "        **{col: df[col].fillna(value).astype(_type) for col, value, _type in zip(cols, values, types)}\n",
    "        # .fillna(value).astype(_type\n",
    "        # fillna(method=\"ffill\", limit=2)\n",
    "    )\n",
    "\n",
    "def display_missing_values(df):\n",
    "    for i, munc in df.groupby('KOMMUNE'):\n",
    "        print(f\"Missing values for {i}\")\n",
    "        display(\n",
    "            munc\n",
    "            # assign null if False else 1\n",
    "            .groupby('ID')\n",
    "            [SENSOR_COLUMNS + ['SKEMALAGT', 'TYPE']]\n",
    "            .apply(lambda x: x.isnull().sum()/len(x))\n",
    "            .style.format(precision=2)\n",
    "            .background_gradient(cmap='Reds', axis=0, vmin=0, vmax=1)\n",
    "        )\n",
    "    return df\n",
    "\n",
    "    \n",
    "def merge_dt(df, date, time, name, sep=\" \"):\n",
    "    return df.assign(\n",
    "        **{name: lambda d: pd.to_datetime(\n",
    "                d[date] + sep + d[time]\n",
    "            )\n",
    "        }\n",
    "    )\n",
    "\n",
    "def drop_cols(df, cols):\n",
    "    return df.drop(columns=cols)\n",
    "\n",
    "def filter_values(df, col, values):\n",
    "    return df[lambda d: d[col].isin(values)]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data = (\n",
    "    pd.read_csv(\"data/Skemaer.csv\")\n",
    "    .pipe(drop_cols, cols=[\"KOMMUNE_DATO_LOKALE_TIME\"])\n",
    "    .pipe(diagnose, col=\"KOMMUNE\", dfunc=\"unique\")\n",
    "    # .pipe(display_missing_values)\n",
    "    .pipe(merge_dt, date=\"DATE\", time=\"TIME\", name=\"DATETIME\")\n",
    "    .pipe(fill_na, \n",
    "        cols=[\"CO2\", \"TEMP\", \"MOTION\", \"IAQ\"],\n",
    "        values=[487, 20.0, 0.0, .03],\n",
    "        types=[float, float, float, float]\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter on 'KOMMUNE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Selecting data for {KOMMUNE}\")\n",
    "dataf = full_data.pipe(filter_values, col=\"KOMMUNE\", values=[KOMMUNE])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    dataf.TEMP.value_counts(bins=3)\n",
    "    .reset_index()\n",
    "    .astype({\"TEMP\": \"str\"})\n",
    "    .sort_values(\"TEMP\", key=lambda d: d.str.extract(r\"\\((.+)\\,\", expand=False).astype(float))\n",
    "    .plot(x=\"TEMP\", y=\"count\", kind=\"bar\", title=\"TEMP distribution\", text=\"count\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    dataf.CO2.value_counts(bins=10)\n",
    "    .reset_index()\n",
    "    .astype({\"CO2\": \"str\"})\n",
    "    .sort_values(\"CO2\", key=lambda d: d.str.extract(r\"\\((.+)\\,\", expand=False).astype(float))\n",
    "    .plot(x=\"CO2\", y=\"count\", kind=\"bar\", title=\"CO2 levels\", text=\"count\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    dataf.MOTION.value_counts()\n",
    "    .reset_index()\n",
    "    .astype({\"MOTION\": \"str\"})\n",
    "    .sort_values(\"MOTION\", key=lambda d: d.str.extract(r\"\\((.+)\\,\", expand=False).astype(float))\n",
    "    .plot(x=\"MOTION\", y=\"count\", kind=\"bar\", log_y=True, title=\"MOTION triggers, log scale\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    dataf.IAQ.value_counts(bins=10)\n",
    "    .reset_index()\n",
    "    .astype({\"IAQ\": \"str\"})\n",
    "    .sort_values(\"IAQ\", key=lambda d: d.str.extract(r\"\\((.+)\\,\", expand=False).astype(float))\n",
    "    .plot(x=\"IAQ\", y=\"count\", kind=\"bar\", title=\"IAQ levels\", text=\"count\", log_y=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show variables over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Showing {dataf.ID.nunique()} rooms\")\n",
    "# for i, df in dataf.groupby(\"ID\"):\n",
    "(\n",
    "    dataf\n",
    "    .melt(id_vars = [\"DATETIME\", \"ID\"], value_vars=[\"CO2\", \"TEMP\", \"MOTION\", \"IAQ\"], var_name=\"Type\")\n",
    "    .plot(\n",
    "        x=\"DATETIME\",\n",
    "        y=\"value\",\n",
    "        facet_row=\"Type\",\n",
    "        # title=f\"V\",\n",
    "        color=\"ID\",\n",
    "    )\n",
    "    .update_yaxes(matches=None)\n",
    "    .update_traces(connectgaps=False)\n",
    ").show(config={\n",
    "            # 'displayModeBar': False, \n",
    "            # \"staticPlot\": True\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing values after imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    (\n",
    "        dataf\n",
    "        .count(0) / len(dataf)\n",
    "    )\n",
    "    .rename(\"purity\")\n",
    "    .plot\n",
    "    .bar(\n",
    "        title=\"Data purity\",\n",
    "        range_y=(0,1),\n",
    "        height=300,\n",
    "        text=\"value\",\n",
    "        labels={\"variable\": \"col\"},\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each room, drop sequences of rows where CO2 is constant, indicating that the sensor is not working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify intervals of 5+ rows of identical values\n",
    "to_drop = (\n",
    "    dataf.groupby(\"ID\")\n",
    "    [\"CO2\"].transform(\n",
    "        lambda x: x.rolling(5).apply(\n",
    "            lambda x: x.nunique() == 1\n",
    "        )\n",
    "    )\n",
    ")\n",
    "cdataf = dataf.drop(index=to_drop[lambda d: d.eq(1.0)].index)\n",
    "f\"Turns {dataf.shape[0]} rows into {cdataf.shape[0]} rows - Dropping {(dataf.shape[0] - cdataf.shape[0])/1000}K rows\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Showing {cdataf.ID.nunique()} rooms\")\n",
    "# for i, df in cdataf.groupby(\"ID\"):\n",
    "(\n",
    "    cdataf\n",
    "    .melt(id_vars = [\"DATETIME\", \"ID\"], value_vars=[\"CO2\", \"TEMP\", \"MOTION\", \"IAQ\"], var_name=\"Type\")\n",
    "    .plot(\n",
    "        x=\"DATETIME\",\n",
    "        y=\"value\",\n",
    "        facet_row=\"Type\",\n",
    "        # title=f\"V\",\n",
    "        color=\"ID\",\n",
    "    )\n",
    "    .update_yaxes(matches=None)\n",
    "    .update_traces(connectgaps=False)\n",
    ").show(config={\n",
    "            # 'displayModeBar': False, \n",
    "            # \"staticPlot\": True\n",
    "        })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Aarhus, we don't have sufficient data for 02.S.09 and 12.S.20."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_date_range_group(grp):\n",
    "    grp['DATE_RANGE_GROUP'] = grp['DATETIME'].transform(lambda x: (x.diff().dt.total_seconds()/ 60).ne(15).cumsum())\n",
    "    return grp\n",
    "\n",
    "\n",
    "\n",
    "data = (\n",
    "    cdataf.sort_values(\"DATETIME\").groupby(\"ID\").apply(add_date_range_group)\n",
    "    .reset_index(drop=True)\n",
    "    .assign(\n",
    "        \n",
    "        CO2_ACC=lambda d: d.groupby([\"ID\", \"DATE_RANGE_GROUP\"])[\"CO2\"].pct_change(fill_method=\"ffill\").fillna(0),\n",
    "        TEMP_ACC=lambda d: d.groupby([\"ID\", \"DATE_RANGE_GROUP\"])[\"TEMP\"].pct_change(fill_method=\"ffill\").fillna(0),\n",
    "        MOTION_ACC=lambda d: d.groupby([\"ID\", \"DATE_RANGE_GROUP\"])[\"MOTION\"].pct_change(fill_method=\"ffill\").fillna(0),\n",
    "        IAQ_ACC=lambda d: d.groupby([\"ID\", \"DATE_RANGE_GROUP\"])[\"IAQ\"].pct_change(fill_method=\"ffill\").fillna(0),\n",
    "    )\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    data\n",
    "    .melt(\n",
    "        id_vars = [\"DATETIME\", \"ID\"],\n",
    "        value_vars=[\"CO2_ACC\", \"TEMP_ACC\", \"MOTION_ACC\", \"IAQ_ACC\"],\n",
    "        var_name=\"Type\"\n",
    "    )\n",
    "    .plot(\n",
    "        x=\"DATETIME\",\n",
    "        y=\"value\",\n",
    "        facet_row=\"Type\",\n",
    "        # title=f\"V\",\n",
    "        color=\"ID\",\n",
    "    )\n",
    "    .update_yaxes(matches=None)\n",
    "    .update_traces(connectgaps=False)\n",
    "    .for_each_annotation(lambda a: a.update(text=a.text.split(\"=\")[-1]))\n",
    ").show(config={\n",
    "            # 'displayModeBar': False,\n",
    "            # \"staticPlot\": True\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.SKEMALAGT.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data = (\n",
    "    data\n",
    "    .assign(\n",
    "        AKTIVITET=lambda d: pd.factorize(d[\"TIDSPUNKT_TYPE\"])[0],\n",
    "        DOW=lambda d: d[\"DATETIME\"].dt.dayofweek,\n",
    "        HOUR=lambda d: d[\"DATETIME\"].dt.hour,\n",
    "        DAY_TYPE=lambda d: pd.factorize(d[\"TYPE\"])[0],\n",
    "        BOOKET=lambda d: d[\"BOOKET\"].fillna(0.0),\n",
    "        \n",
    "    )\n",
    "    .drop(columns=[\n",
    "        \"DATE\",\n",
    "        \"TIDSPUNKT_TYPE\",\n",
    "        \"TYPE\",\n",
    "        \"DATE_RANGE_GROUP\",\n",
    "        \"DAYNAME\",\n",
    "        \"TIME\",\n",
    "        \"SKOLE\",\n",
    "        \"KOMMUNE\",\n",
    "        \"NAVN\"\n",
    "        ]\n",
    "    )\n",
    "\n",
    "       # anomaly detection variables\n",
    "    # .assign(EST_USE=lambda d: (d[\"SKEMALAGT\"] | d[\"BOOKET\"]).astype(\"category\"))\n",
    "    # .assign(CO2_ACC=lambda d: (d[\"CO2\"] + 1).pct_change())\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pearson correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    model_data\n",
    "    .drop(columns=[\"DATETIME\", \"ID\"])\n",
    "    .corr()\n",
    "    .dropna(axis=0, how='all')\n",
    "    .dropna(axis=1, how='all')\n",
    "    .pipe(px.imshow, text_auto='.3f', width=1000)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing for modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = model_data.ID.value_counts().head(3)\n",
    "EX1_ID = examples.index[1]\n",
    "display(examples)\n",
    "EX1_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est_usage = 2.1 * (model_data[\"SKEMALAGT\"].astype(bool) | model_data[\"BOOKET\"].astype(bool)).sum() / model_data.shape[0]\n",
    "est_usage "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_predict(df, usage=est_usage, n_estimators=500, random_state=42):\n",
    "    model_IF = IsolationForest(\n",
    "        usage=0.4, #est_usage,\n",
    "        random_state=random_state,\n",
    "        n_estimators=n_estimators,\n",
    "        verbose=1\n",
    "    )\n",
    "    model_IF.fit(df)\n",
    "\n",
    "    scores = model_IF.decision_function(df)\n",
    "    predictions = model_IF.predict(df)\n",
    "    return scores, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_results(dataf, scores, predictions):\n",
    "    return (\n",
    "        pd.DataFrame(\n",
    "            {\n",
    "                'DATETIME': dataf['DATETIME'],\n",
    "                'usage_score': scores,\n",
    "                'usage': predictions,\n",
    "                'CO2': dataf['CO2'],\n",
    "                # 'CO2_ACC': dataf['CO2_ACC'],\n",
    "                # 'MOTION': dataf['MOTION'],\n",
    "                # 'IAQ_ACC': dataf['IAQ_ACC'],\n",
    "            }\n",
    "        )\n",
    "        .astype({\"usage\": \"category\"})\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EX_FEATURES = EX[[\n",
    "    # 'ID',\n",
    "    'SKEMALAGT',\n",
    "    # 'CO2',\n",
    "    # 'TEMP',\n",
    "    # 'MOTION',\n",
    "    # 'IAQ',\n",
    "    # 'BOOKET',\n",
    "    # 'DATETIME',\n",
    "    'CO2_ACC',\n",
    "    'TEMP_ACC',\n",
    "    # 'MOTION_ACC',\n",
    "    # 'IAQ_ACC',\n",
    "    # 'AKTIVITET',\n",
    "    # 'DOW',\n",
    "    # 'HOUR',\n",
    "    # 'DAY_TYPE'\n",
    "]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores, predictions = fit_predict(EX_FEATURES, n_estimators=100, usage=est_usage)\n",
    "\n",
    "results = format_results(EX, scores, predictions)\n",
    "results.usage.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    results.usage_score.value_counts(bins=10)\n",
    "    .reset_index()\n",
    "    .astype({\"usage_score\": str})\n",
    "    .sort_values(\"usage_score\", key=lambda d: d.str.extract(r\"\\((.+)\\,\", expand=False).astype(float))\n",
    "    .plot(x=\"usage_score\", y=\"count\", kind=\"bar\", title=\"IF anomaly score distribution\", text=\"count\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = (\n",
    "    (\n",
    "        results\n",
    "        .assign(CO2_ACC=EX[\"CO2_ACC\"])\n",
    "        .assign(\n",
    "            usage=lambda d: np.where(\n",
    "                d[\"CO2\"].lt(600),\n",
    "                1,\n",
    "                d[\"usage\"],\n",
    "            ),\n",
    "        )\n",
    "        .assign(\n",
    "            usage=lambda d: np.where(\n",
    "                (d[\"CO2_ACC\"].gt(.1) & d[\"CO2\"].gt(600)) | (d[\"CO2\"].gt(1200)),\n",
    "                -1, \n",
    "                d[\"usage\"]\n",
    "            )\n",
    "        )\n",
    "        # [lambda d: (d[\"DATETIME\"] > \"2022-08-09\") & (d[\"DATETIME\"] <= \"2022-11-01\")]\n",
    "    ).plot.bar(    \n",
    "    x='DATETIME',\n",
    "    y='CO2',\n",
    "    color='usage',\n",
    "    title='CO2 anomaly',\n",
    "    width=3000,\n",
    "    hover_data=EX[[\"CO2_ACC\"]],\n",
    ")\n",
    ")\n",
    "# fig[\"layout\"][\"xaxis\"].update(range=[\"2022-08-09\", \"2023-01-01\"]) \n",
    "fig.update_traces(dict(marker_line_width=0))\n",
    "fig.write_html(f'anomaly-{KOMMUNE}-{EX1_ID}.html')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process for delivery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction flow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "******"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_predict(df, usage=0.19, n_estimators=500, random_state=42):\n",
    "    model_IF = IsolationForest(\n",
    "        usage=0.4, #est_usage,\n",
    "        random_state=random_state,\n",
    "        n_estimators=n_estimators,\n",
    "        verbose=1\n",
    "    )\n",
    "    model_IF.fit(df)\n",
    "\n",
    "    scores = model_IF.decision_function(df)\n",
    "    predictions = model_IF.predict(df)\n",
    "    return scores, predictions\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est_usage = 2.1 * (model_data[\"SKEMALAGT\"].astype(bool) | model_data[\"BOOKET\"].astype(bool)).sum() / model_data.shape[0]\n",
    "est_usage "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(data, features):\n",
    "\n",
    "    scores, predictions = fit_predict(\n",
    "        data[features], \n",
    "        n_estimators=100, \n",
    "        usage=est_usage,\n",
    "    )\n",
    "    data[\"usage_score\"] = scores\n",
    "    data[\"usage\"] = predictions\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_heuristics(data):\n",
    "    return(\n",
    "        data\n",
    "        .assign(\n",
    "            usage=lambda d: np.where(\n",
    "                d[\"CO2\"].lt(600),\n",
    "                1,\n",
    "                d[\"usage\"],\n",
    "            ),\n",
    "        )\n",
    "        .assign(\n",
    "            usage=lambda d: np.where(\n",
    "                (d[\"CO2_ACC\"].gt(.1) & d[\"CO2\"].gt(600)) | (d[\"CO2\"].gt(1200)),\n",
    "                -1, \n",
    "                d[\"usage\"]\n",
    "            )\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_plots(data, kommune):\n",
    "\n",
    "    for i, dataf in data.groupby(\"ID\"):\n",
    "        fig = dataf.plot.bar(    \n",
    "            x='DATETIME',\n",
    "            y='CO2',\n",
    "            color='usage',\n",
    "            title=f'Anvendelsesmodel - Lokale {i} - {kommune} Kommune',\n",
    "            width=3000,\n",
    "            hover_data=dataf[[\"CO2_ACC\"]],\n",
    "        )\n",
    "        fig.update_traces(dict(marker_line_width=0))\n",
    "        fig.write_html(f'result_plots/{kommune}/anomaly-{kommune.lower()}-{i}.html')\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "room_features = [\"SKEMALAGT\", \"CO2_ACC\", \"TEMP_ACC\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataf = (\n",
    "    model_data\n",
    "    .sort_values([\"DATETIME\", \"ID\"])\n",
    "    .groupby(\"ID\").apply(run_model, features=room_features)\n",
    "    .reset_index(drop=True)\n",
    "    .pipe(add_heuristics)\n",
    "    .pipe(export_plots, kommune=KOMMUNE)\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
