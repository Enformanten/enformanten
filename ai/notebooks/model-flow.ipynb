{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Flow\n",
    "\n",
    "This notebook contains a step-by-step guide to the model registry flow. It is intended to be used as a reference to understand the operations performed to create each moddel, and as a starting point for future development."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install rich # Run this cell if you don't have rich installed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import packages. Note that `tilly` is our internal name for Driftsoptimeringsmodellen. <br>\n",
    "(Utilization model -> Utilization -> Tilly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.orm import Session\n",
    "from typing import Generator\n",
    "from loguru import logger\n",
    "\n",
    "from tilly.config import SNOWFLAKE_URL\n",
    "from tilly.database.data.models import TrainingTimeslots\n",
    "from tilly.services.ml.transformations.preprocessing import Preprocessor\n",
    "from tilly.services.ml.model import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.plotting.backend = \"plotly\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the snowflake connection and retrieve data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(SNOWFLAKE_URL, future=True)\n",
    "\n",
    "def get_session() -> Generator[Session, None, None]:\n",
    "    with Session(engine) as session:\n",
    "        yield session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve a single room from the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_data(session: Session, table: object) -> dict[str, pd.DataFrame]:\n",
    "    \"\"\"retrieve all timeslots using sqlalchemy\"\"\"\n",
    "    logger.debug(f\"Retrieving data from {table.__tablename__}\")\n",
    "\n",
    "    query = session.query(table).limit(1000).statement\n",
    "\n",
    "    # Step 1: Identify the first unique combination of SKOLE and ID\n",
    "    first_unique_combo = (\n",
    "        session.query(table.school, table.room_id)\n",
    "        .group_by(table.school, table.room_id)\n",
    "        .order_by(table.school, table.room_id)\n",
    "        .first()\n",
    "    )\n",
    "\n",
    "    # Step 2: Retrieve all rows that match the first unique combination of SKOLE and room_id\n",
    "    if first_unique_combo:\n",
    "        skole_value, room_id_value = first_unique_combo\n",
    "        query = session.query(table).filter_by(school=skole_value, room_id=room_id_value).statement\n",
    "\n",
    "\n",
    "        data = {\n",
    "            school_room: df\n",
    "            for school_room, df in (\n",
    "                pd.read_sql(query, session.bind)\n",
    "                .assign(\n",
    "                    SKOLE_ID=lambda d: d.SKOLE + \"_\" + d.ID,\n",
    "                    DATETIME=lambda d: pd.to_datetime(d[\"DATE\"].astype(str) + \" \" + d[\"TIME\"].astype(str))\n",
    "                )\n",
    "                .sort_values(\"DATETIME\")\n",
    "                .rename(str, axis=\"columns\")\n",
    "                .groupby(\"SKOLE_ID\")\n",
    "            )\n",
    "    }\n",
    "    return data\n",
    "\n",
    "room = retrieve_data(next(get_session()),table=TrainingTimeslots)\n",
    "f\"{room.keys()=}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = room[list(room.keys())[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_col(df, x = \"DATETIME\", y = \"CO2\", **kwargs):\n",
    "    if not df.empty:\n",
    "        fig = df.plot.bar(\n",
    "            x=\"DATETIME\",\n",
    "            y=\"CO2\",\n",
    "            title=f\"{y} values for {df.SKOLE_ID.iloc[0]}\",\n",
    "            **kwargs\n",
    "            # prevent stacking CO2 values on same dates\n",
    "        )\n",
    "        fig.update_traces(dict(marker_line_width=0))\n",
    "        fig.show()\n",
    "    else:\n",
    "        print(\"No data to plot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_col(data) # Rønbækskolen_E.16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run preprocessing flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep = Preprocessor()\n",
    "\n",
    "processed = (\n",
    "    data\n",
    "\n",
    "    # fill missing timeslots between first and last timeslot\n",
    "    .pipe(prep.add_missing_timeslots)\n",
    "\n",
    "    # fill missing values using cubic spline interpolation\n",
    "    .pipe(prep.interpolate_missing_islands, target_col=\"CO2\", limit=4)\n",
    "\n",
    "    # remove timeslots where 5 or more consecutive values are missing\n",
    "    .pipe(prep.remove_stagnate_intervals, target_col=\"CO2\", threshold=5)\n",
    "\n",
    "    # remove all rows where CO2 is missing\n",
    "    .dropna(subset=[\"CO2\"])\n",
    "\n",
    "    # drop timeslots where CO2 is outside the bounds of 1 and 8000\n",
    "    .pipe(prep.drop_outliers, bounds={\"CO2\": (1, 8000)})\n",
    "\n",
    "    # remove days where less than 25% of the timeslots are present\n",
    "    .pipe(prep.day_filter, min_ratio=0.25)\n",
    "\n",
    "    # group timeslots into time-contiguous groups\n",
    "    .pipe(\n",
    "        prep.apply_time_group_funcs,\n",
    "        funcs=[\n",
    "\n",
    "            # Apply gaussian smoothing to CO2 values\n",
    "            (prep.gaussian_smooth, dict(metric=\"CO2\", std_dev=2)),\n",
    "            (\n",
    "                # calculate derivatives of CO2 values\n",
    "                prep.calculate_kinematic_quantities,\n",
    "                dict(metric=\"CO2_smoothed\", window=4, prefix=\"CO2\"),\n",
    "            ),\n",
    "        ],\n",
    "    )\n",
    "    # add time features\n",
    "    .pipe(prep.add_time_features, night_start=22, night_end=6)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "FEATURES = [\n",
    "    # \"CO2\",\n",
    "    \"CO2_velocity\",\n",
    "    \"CO2_acceleration\",\n",
    "    # \"CO2_jerk\",\n",
    "    \"CO2_smoothed\",\n",
    "    \"is_night\",\n",
    "    \"CO2_log\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(\n",
    "    model_params={\n",
    "        \"n_estimators\": 300,\n",
    "        \"random_state\": 123,\n",
    "        \"verbose\": 0,\n",
    "\n",
    "    },\n",
    "    estimated_usage=0.3\n",
    ")\n",
    "model.fit(processed[FEATURES])\n",
    "processed[\"pred\"] = model.predict(processed[FEATURES])\n",
    "processed[\"score\"] = model.score(processed[FEATURES])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting using Plotly via Pandas\n",
    "(\n",
    "    processed.assign(color=lambda d: d[\"pred\"].map({0: 'Unsued', 1: 'Used'})).plot.bar(\n",
    "        x='DATETIME',\n",
    "        y=['CO2'], \n",
    "        color=\"color\", \n",
    "        hover_data=[\"CO2_velocity\", \"score\"], \n",
    "        barmode=\"group\", \n",
    "    )\n",
    "    .update_layout(\n",
    "        title='Usage detection',\n",
    "        xaxis_title='Time',\n",
    "        yaxis_title='CO2 level',\n",
    "        legend_title=\"Usage\",          \n",
    "    )\n",
    "    .update_traces(dict(marker_line_width=0))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Postprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heuristics(room: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Add heuristic rules to predicted data\"\"\"\n",
    "    \n",
    "\n",
    "    def apply_night_time_filter(df):\n",
    "        \"\"\"Filters out false positives during midnight to 6 AM.\"\"\"\n",
    "        hour = df[\"DATETIME\"].dt.hour\n",
    "        mask = (hour >= 0) & (hour < 6) & (df[\"ANOMALY_SCORE\"] <= 0.7)\n",
    "        df.loc[mask, \"IN_USE\"] = 0\n",
    "        return df\n",
    "\n",
    "    def apply_stand_alone_instances_filter(df):\n",
    "        \"\"\"Removes isolated instances of \"IN_USE\" being 1.\"\"\"\n",
    "        prev_IN_USE = df[\"IN_USE\"].shift(1, fill_value=0)\n",
    "        next_IN_USE = df[\"IN_USE\"].shift(-1, fill_value=0)\n",
    "        mask = (prev_IN_USE == 0) & (df[\"IN_USE\"] == 1) & (next_IN_USE == 0)\n",
    "        df.loc[mask, \"IN_USE\"] = 0\n",
    "        return df\n",
    "\n",
    "    def apply_low_co2_filter(df):\n",
    "        \"\"\"Sets \"IN_USE\" to 0 if CO2 levels are low.\"\"\"\n",
    "        mask = df[\"CO2\"] <= 325\n",
    "        df.loc[mask, \"IN_USE\"] = 0\n",
    "        return df\n",
    "\n",
    "    def update_anomaly_score(df):\n",
    "        \"\"\"Updates the anomaly score based on the modified\n",
    "        \"IN_USE\" values.\"\"\"\n",
    "        mask = ((df[\"IN_USE\"] == 1) & (df[\"ANOMALY_SCORE\"] < 0.5)) | (\n",
    "            (df[\"IN_USE\"] == 0) & (df[\"ANOMALY_SCORE\"] > 0.5)\n",
    "        )\n",
    "        df.loc[mask, \"ANOMALY_SCORE\"] = 1 - df.loc[mask, \"ANOMALY_SCORE\"]\n",
    "        return df\n",
    "\n",
    "    return (\n",
    "        room.pipe(apply_night_time_filter)\n",
    "        .pipe(apply_stand_alone_instances_filter)\n",
    "        .pipe(apply_low_co2_filter)\n",
    "        .pipe(update_anomaly_score)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "postprocessed = heuristics(processed.rename(columns={\"pred\": \"IN_USE\", \"score\": \"ANOMALY_SCORE\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize results after postprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    postprocessed.assign(color=lambda d: d[\"IN_USE\"].map({0: 'blue', 1: 'red'})).plot.bar(\n",
    "        x='DATETIME',\n",
    "        y=['CO2'], \n",
    "        color=\"color\", \n",
    "        hover_data=[\"CO2_velocity\", \"ANOMALY_SCORE\"], \n",
    "        barmode=\"group\", \n",
    "    )\n",
    "    .update_layout(\n",
    "        title='Usage detection - Heuristics',\n",
    "        xaxis_title='Time',\n",
    "        yaxis_title='CO2 level',\n",
    "        legend_title=\"Usage\",          \n",
    "    )\n",
    "    .update_traces(dict(marker_line_width=0))\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tilly-s2H1s5Sc-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
